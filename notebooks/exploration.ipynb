{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting future sales for Rossmann Pharmaceuticals across various stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import logging, sys, os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Coop\\AppData\\Local\\Temp\\ipykernel_14956\\3063719074.py:13: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_df = pd.read_csv('../data/raw/train.csv')\n",
      "2025-01-02 10:08:11,100 - INFO - Datasets loaded successfully.\n",
      "2025-01-02 10:08:11,102 - INFO - Preview of training data:\n",
      "2025-01-02 10:08:11,103 - INFO - Training data summary:\n",
      "2025-01-02 10:08:11,103 - INFO - Preview of store data:\n",
      "2025-01-02 10:08:11,108 - INFO - Store data summary:\n",
      "2025-01-02 10:08:11,254 - INFO - Datasets merged successfully. Combined dataset preview:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store StoreType Assortment  CompetitionDistance  CompetitionOpenSinceMonth  \\\n",
      "0      1         c          a               1270.0                        9.0   \n",
      "1      2         a          a                570.0                       11.0   \n",
      "2      3         a          a              14130.0                       12.0   \n",
      "3      4         c          c                620.0                        9.0   \n",
      "4      5         a          a              29910.0                        4.0   \n",
      "\n",
      "   CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear  \\\n",
      "0                    2008.0       0              NaN              NaN   \n",
      "1                    2007.0       1             13.0           2010.0   \n",
      "2                    2006.0       1             14.0           2011.0   \n",
      "3                    2009.0       0              NaN              NaN   \n",
      "4                    2015.0       0              NaN              NaN   \n",
      "\n",
      "     PromoInterval  \n",
      "0              NaN  \n",
      "1  Jan,Apr,Jul,Oct  \n",
      "2  Jan,Apr,Jul,Oct  \n",
      "3              NaN  \n",
      "4              NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 10:08:11,445 - INFO - Missing values in the dataset:\n",
      "CompetitionDistance            2642\n",
      "CompetitionOpenSinceMonth    323348\n",
      "CompetitionOpenSinceYear     323348\n",
      "Promo2SinceWeek              508031\n",
      "Promo2SinceYear              508031\n",
      "PromoInterval                508031\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configure logger\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load data\n",
    "try:\n",
    "    train_df = pd.read_csv('../data/raw/train.csv')\n",
    "    store_df = pd.read_csv('../data/raw/store.csv')\n",
    "    logger.info(\"Datasets loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    logger.error(f\"Error loading datasets: {e}\")\n",
    "    raise\n",
    "\n",
    "# Display initial information\n",
    "logger.info(\"Preview of training data:\")\n",
    "# print(train_df.head())\n",
    "logger.info(\"Training data summary:\")\n",
    "# print(train_df.info())\n",
    "\n",
    "logger.info(\"Preview of store data:\")\n",
    "print(store_df.head())\n",
    "logger.info(\"Store data summary:\")\n",
    "# print(store_df.info())\n",
    "\n",
    "# Merge train and store datasets\n",
    "# df = pd.merge(train_df, store_df, on='Store', how='left')\n",
    "# logger.info(\"Datasets merged successfully. Combined dataset preview:\")\n",
    "# print(df.head())\n",
    "\n",
    "# Check for missing values\n",
    "# missing_data = df.isnull().sum()\n",
    "# logger.info(f\"Missing values in the dataset:\\n{missing_data[missing_data > 0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
